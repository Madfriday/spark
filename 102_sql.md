### sparkSQL

* 与RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上 看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。由于与R和Pandas的DataFrame类似，Spark DataFrame很好地继承了传统单机数据分析的开发体验。  

* sparksql基本使用
```
spark 1.x SQL的基本用法（两种）

1.创建SparkContext
2.创建SQLContext
3.创建RDD
4.创建一个类，并定义类的成员变量
5.整理数据并关联class
6.将RDD转换成DataFrame（导入隐式转换）
7.将DataFrame注册成临时表
8.书写SQL（Transformation）
9.执行Action
---------------------------------
1.创建SparkContext
2.创建SQLContext
3.创建RDD
4.创建StructType（schema）
5.整理数据将数据跟Row关联
6.通过rowRDD和schema创建DataFrame
7.将DataFrame注册成临时表
8.书写SQL（Transformation）
9.执行Action
---------------------------------
---------------------------------
Spark Core : RDD 
Spark SQL : DataFrame , DataSet

DataFrame是关联的schema信息的RDD
DataSet相当于是优化过了的RDD


for(i <- 1 to 10) {
	println(i)
}
pritnln(1)
println(2)
pritnln(3)
println(4)
row number parition by
```

